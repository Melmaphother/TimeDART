python -u run.py \
    --task_name finetune \
    --downstream_task classification \
    --root_path datasets/har_no_big/ \
    --model_id HAR \
    --model TimeDART \
    --data HAR \
    --e_layers 2 \
    --d_layers 1 \
    --input_len 128 \
    --enc_in 9 \
    --dec_in 9 \
    --c_out 9 \
    --num_classes 6 \
    --n_heads 8 \
    --d_model 64 \
    --d_ff 256 \
    --patch_len 8 \
    --stride 8 \
    --head_dropout 0.1 \
    --dropout 0.2 \
    --time_steps 1000 \
    --scheduler cosine \
    --batch_size 128 \
    --gpu 0 \
    --lr_decay 0.99 \
    --lradj step \
    --scheduler cosine \
    --patience 100 \
    --learning_rate 0.0005 \
    --pct_start 0.3 \
    --train_epochs 100
